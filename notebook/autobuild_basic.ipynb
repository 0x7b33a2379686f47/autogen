{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1004af6a7fbfcd8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# AutoBuild\n",
    "By: [Linxin Song](https://linxins97.github.io/), [Jieyu Zhang](https://jieyuz2.github.io/)\n",
    "Reference: [Agent AutoBuild](https://microsoft.github.io/autogen/blog/2023/11/26/Agent-AutoBuild/)\n",
    "\n",
    "AutoGen offers conversable agents powered by LLM, tool, or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "In this notebook, we introduce a new class, `AgentBuilder`, to help user build an automatic task solving process powered by multi-agent system. Specifically, in `build()`, we prompt a LLM to create multiple participant agent and initialize a group chat, and specify whether this task need programming to solve. AgentBuilder also support open-source LLMs by [vLLM](https://docs.vllm.ai/en/latest/index.html) and [Fastchat](https://github.com/lm-sys/FastChat). Check the supported model list [here](https://docs.vllm.ai/en/latest/models/supported_models.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78dda8e3826d8a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Requirement\n",
    "\n",
    "AutoBuild need the latest version of AutoGen.\n",
    "You can install AutoGen by the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e9ae50658be975",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install pyautogen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0e63ab3604bdb9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 1: prepare configuration and some useful functions\n",
    "Prepare a `config_path` for assistant agent to limit the choice of LLM you want to use in this task. This config can be a path of json file or a name of environment variable. A `default_llm_config` is also required for initialize the specific config of LLMs like seed, temperature, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2505f029423b21ab",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T09:18:00.914574500Z",
     "start_time": "2024-01-01T09:18:00.478298700Z"
    }
   },
   "outputs": [],
   "source": [
    "import autogen\n",
    "from autogen.agentchat.contrib.agent_builder import AgentBuilder\n",
    "\n",
    "config_path = 'OAI_CONFIG_LIST'  # modify path\n",
    "default_llm_config = {\n",
    "    'temperature': 0\n",
    "}\n",
    "\n",
    "def start_task(execution_task: str, agent_list: list, llm_config: dict):\n",
    "    config_list = autogen.config_list_from_json(config_path, filter_dict={\"model\": [\"gpt-4-1106-preview\"]})\n",
    "    \n",
    "    group_chat = autogen.GroupChat(agents=agent_list, messages=[], max_round=12)\n",
    "    manager = autogen.GroupChatManager(\n",
    "        groupchat=group_chat, llm_config={\"config_list\": config_list, **llm_config}\n",
    "    )\n",
    "    agent_list[0].initiate_chat(manager, message=execution_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d6586c68fa425b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 2: create a AgentBuilder\n",
    "Create a `AgentBuilder` with the specified `config_path`. AgentBuilder will use `gpt-4` in default to complete the whole process, you can specify the `builder_model` and `agent_model` to other OpenAI model to match your task. \n",
    "You can also specify an open-source LLM supporting by vLLM and FastChat, see blog for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfa67c771a0fed37",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T09:18:01.164216400Z",
     "start_time": "2024-01-01T09:18:00.917678900Z"
    }
   },
   "outputs": [],
   "source": [
    "builder = AgentBuilder(config_path=config_path, builder_model='gpt-4-1106-preview', agent_model='gpt-4-1106-preview')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a655fb6618324",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 3: specify a building task\n",
    "\n",
    "Specify a building task with a general description. Building task will help build manager (a LLM) decide what agents should be built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68315f6ec912c58a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T09:18:01.215630200Z",
     "start_time": "2024-01-01T09:18:01.165908800Z"
    }
   },
   "outputs": [],
   "source": [
    "building_task = \"Find a paper on arxiv by programming, and analyze its application in some domain. For example, find a recent paper about gpt-4 on arxiv and find its potential applications in software.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5782dd5ecb6c217a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 4: build group chat agents\n",
    "Use `build()` to let build manager (the specified `builder_model`) complete the group chat agents generation. If you think coding is necessary in your task, you can use `coding=True` to add a user proxy (an automatic code interpreter) into the agent list, like: \n",
    "```python\n",
    "builder.build(building_task, default_llm_config, coding=True)\n",
    "```\n",
    "If `coding` is not specified, AgentBuilder will determine on its own whether the user proxy should be added or not according to the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab490fdbe46c0473",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:56:22.176587900Z",
     "start_time": "2024-01-01T08:54:37.702562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Generating agents...\n",
      "['Data_scientist', 'Machine_learning_engineer', 'Natural_language_processing_specialist', 'Arxiv_API_developer', 'Application_analyst'] are generated.\n",
      "==> Generating system message...\n",
      "Preparing system message for Data_scientist\n",
      "Preparing system message for Machine_learning_engineer\n",
      "Preparing system message for Natural_language_processing_specialist\n",
      "Preparing system message for Arxiv_API_developer\n",
      "Preparing system message for Application_analyst\n",
      "==> Generating description...\n",
      "Preparing description for Data_scientist\n",
      "Preparing description for Machine_learning_engineer\n",
      "Preparing description for Natural_language_processing_specialist\n",
      "Preparing description for Arxiv_API_developer\n",
      "Preparing description for Application_analyst\n",
      "==> Creating agents...\n",
      "Creating agent Data_scientist with backbone gpt-4-1106-preview...\n",
      "Creating agent Machine_learning_engineer with backbone gpt-4-1106-preview...\n",
      "Creating agent Natural_language_processing_specialist with backbone gpt-4-1106-preview...\n",
      "Creating agent Arxiv_API_developer with backbone gpt-4-1106-preview...\n",
      "Creating agent Application_analyst with backbone gpt-4-1106-preview...\n",
      "Adding user console proxy...\n"
     ]
    }
   ],
   "source": [
    "agent_list, agent_configs = builder.build(building_task, default_llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00dd99880a4bf7b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 5: execute task\n",
    "Let agents generated in `build()` to complete the task collaboratively in a group chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d52e3d9a1bf91cb",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:58:28.707122400Z",
     "start_time": "2024-01-01T08:56:22.167569700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mUser_console_and_Python_code_interpreter\u001B[0m (to chat_manager):\n",
      "\n",
      "Find a recent paper about gpt-4 on arxiv and find its potential applications in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mArxiv_API_developer\u001B[0m (to chat_manager):\n",
      "\n",
      "To begin our task, I will outline the steps we need to take:\n",
      "\n",
      "1. **Search for Papers**: We will use the arXiv API to search for recent papers that mention \"GPT-4\". We'll need to define the query parameters to include the title, abstract, or keywords related to GPT-4.\n",
      "\n",
      "2. **Retrieve and Filter Results**: Once we have the search results, we'll filter them by date to ensure we're looking at the most recent papers.\n",
      "\n",
      "3. **Download and Read Files**: We will select a relevant paper from the results and download it to extract information about potential applications in software development.\n",
      "\n",
      "4. **Analyze Information**: After reading the content of the paper, we will discuss the applications of GPT-4 in software development as mentioned in the paper.\n",
      "\n",
      "5. **Discuss Findings**: We will then analyze the implications of these applications and how they might affect the future of software development.\n",
      "\n",
      "6. **Conclude Task**: Once we have a good understanding of the potential applications and implications, we will conclude our task.\n",
      "\n",
      "Let's start with step 1. I will craft a Python code snippet to search for papers on arXiv that mention \"GPT-4\". Please note that I will not be running the code myself, but I will provide you with the code that you can run in your Python environment.\n",
      "\n",
      "```python\n",
      "import urllib\n",
      "import feedparser\n",
      "\n",
      "# Base API query url\n",
      "base_url = 'http://export.arxiv.org/api/query?'\n",
      "\n",
      "# Search parameters\n",
      "search_query = 'all:GPT-4' # search for the term 'GPT-4' in all fields\n",
      "start = 0                     # start at the first result\n",
      "max_results = 10              # maximum results to return\n",
      "\n",
      "query = f'search_query={search_query}&start={start}&max_results={max_results}'\n",
      "\n",
      "# Perform a GET request using the base_url and query\n",
      "response = urllib.request.urlopen(base_url+query).read()\n",
      "\n",
      "# Parse the response using feedparser\n",
      "feed = feedparser.parse(response)\n",
      "\n",
      "# Print out the titles and summaries for each entry\n",
      "for entry in feed.entries:\n",
      "    print('Title:', entry.title)\n",
      "    print('Authors:', entry.authors)\n",
      "    print('Published:', entry.published)\n",
      "    print('Summary:', entry.summary)\n",
      "    print('arXiv ID:', entry.id.split('/abs/')[-1])\n",
      "    print('Link:', entry.link)\n",
      "    print('---')\n",
      "```\n",
      "\n",
      "This code will print out the titles, authors, publication dates, summaries, arXiv IDs, and links to the papers that mention \"GPT-4\". You can run this code to retrieve the list of papers. Once you have the list, we can move on to the next steps.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001B[0m\n",
      "\u001B[33mUser_console_and_Python_code_interpreter\u001B[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Title: Can LLMs like GPT-4 outperform traditional AI tools in dementia\n",
      "  diagnosis? Maybe, but not today\n",
      "Authors: [{'name': 'Zhuo Wang'}, {'name': 'Rongzhen Li'}, {'name': 'Bowen Dong'}, {'name': 'Jie Wang'}, {'name': 'Xiuxing Li'}, {'name': 'Ning Liu'}, {'name': 'Chenhui Mao'}, {'name': 'Wei Zhang'}, {'name': 'Liling Dong'}, {'name': 'Jing Gao'}, {'name': 'Jianyong Wang'}]\n",
      "Published: 2023-06-02T12:47:45Z\n",
      "Summary: Recent investigations show that large language models (LLMs), specifically\n",
      "GPT-4, not only have remarkable capabilities in common Natural Language\n",
      "Processing (NLP) tasks but also exhibit human-level performance on various\n",
      "professional and academic benchmarks. However, whether GPT-4 can be directly\n",
      "used in practical applications and replace traditional artificial intelligence\n",
      "(AI) tools in specialized domains requires further experimental validation. In\n",
      "this paper, we explore the potential of LLMs such as GPT-4 to outperform\n",
      "traditional AI tools in dementia diagnosis. Comprehensive comparisons between\n",
      "GPT-4 and traditional AI tools are conducted to examine their diagnostic\n",
      "accuracy in a clinical setting. Experimental results on two real clinical\n",
      "datasets show that, although LLMs like GPT-4 demonstrate potential for future\n",
      "advancements in dementia diagnosis, they currently do not surpass the\n",
      "performance of traditional AI tools. The interpretability and faithfulness of\n",
      "GPT-4 are also evaluated by comparison with real doctors. We discuss the\n",
      "limitations of GPT-4 in its current state and propose future research\n",
      "directions to enhance GPT-4 in dementia diagnosis.\n",
      "arXiv ID: 2306.01499v1\n",
      "Link: http://arxiv.org/abs/2306.01499v1\n",
      "---\n",
      "Title: GPT-4 Can't Reason\n",
      "Authors: [{'name': 'Konstantine Arkoudas'}]\n",
      "Published: 2023-07-21T17:04:25Z\n",
      "Summary: GPT-4 was released in March 2023 to wide acclaim, marking a very substantial\n",
      "improvement across the board over GPT-3.5 (OpenAI's previously best model,\n",
      "which had powered the initial release of ChatGPT). However, despite the\n",
      "genuinely impressive improvement, there are good reasons to be highly skeptical\n",
      "of GPT-4's ability to reason. This position paper discusses the nature of\n",
      "reasoning; criticizes the current formulation of reasoning problems in the NLP\n",
      "community, as well as the way in which LLM reasoning performance is currently\n",
      "evaluated; introduces a small collection of 21 diverse reasoning problems; and\n",
      "performs a detailed qualitative evaluation of GPT-4's performance on those\n",
      "problems. Based on this analysis, the paper concludes that, despite its\n",
      "occasional flashes of analytical brilliance, GPT-4 at present is utterly\n",
      "incapable of reasoning.\n",
      "arXiv ID: 2308.03762v2\n",
      "Link: http://arxiv.org/abs/2308.03762v2\n",
      "---\n",
      "Title: Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4\n",
      "Authors: [{'name': 'Hanmeng Liu'}, {'name': 'Ruoxi Ning'}, {'name': 'Zhiyang Teng'}, {'name': 'Jian Liu'}, {'name': 'Qiji Zhou'}, {'name': 'Yue Zhang'}]\n",
      "Published: 2023-04-07T01:37:45Z\n",
      "Summary: Harnessing logical reasoning ability is a comprehensive natural language\n",
      "understanding endeavor. With the release of Generative Pretrained Transformer 4\n",
      "(GPT-4), highlighted as \"advanced\" at reasoning tasks, we are eager to learn\n",
      "the GPT-4 performance on various logical reasoning tasks. This report analyses\n",
      "multiple logical reasoning datasets, with popular benchmarks like LogiQA and\n",
      "ReClor, and newly-released datasets like AR-LSAT. We test the multi-choice\n",
      "reading comprehension and natural language inference tasks with benchmarks\n",
      "requiring logical reasoning. We further construct a logical reasoning\n",
      "out-of-distribution dataset to investigate the robustness of ChatGPT and GPT-4.\n",
      "We also make a performance comparison between ChatGPT and GPT-4. Experiment\n",
      "results show that ChatGPT performs significantly better than the RoBERTa\n",
      "fine-tuning method on most logical reasoning benchmarks. With early access to\n",
      "the GPT-4 API we are able to conduct intense experiments on the GPT-4 model.\n",
      "The results show GPT-4 yields even higher performance on most logical reasoning\n",
      "datasets. Among benchmarks, ChatGPT and GPT-4 do relatively well on well-known\n",
      "datasets like LogiQA and ReClor. However, the performance drops significantly\n",
      "when handling newly released and out-of-distribution datasets. Logical\n",
      "reasoning remains challenging for ChatGPT and GPT-4, especially on\n",
      "out-of-distribution and natural language inference datasets. We release the\n",
      "prompt-style logical reasoning datasets as a benchmark suite and name it\n",
      "LogiEval.\n",
      "arXiv ID: 2304.03439v3\n",
      "Link: http://arxiv.org/abs/2304.03439v3\n",
      "---\n",
      "Title: How is ChatGPT's behavior changing over time?\n",
      "Authors: [{'name': 'Lingjiao Chen'}, {'name': 'Matei Zaharia'}, {'name': 'James Zou'}]\n",
      "Published: 2023-07-18T06:56:08Z\n",
      "Summary: GPT-3.5 and GPT-4 are the two most widely used large language model (LLM)\n",
      "services. However, when and how these models are updated over time is opaque.\n",
      "Here, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on\n",
      "several diverse tasks: 1) math problems, 2) sensitive/dangerous questions, 3)\n",
      "opinion surveys, 4) multi-hop knowledge-intensive questions, 5) generating\n",
      "code, 6) US Medical License tests, and 7) visual reasoning. We find that the\n",
      "performance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time.\n",
      "For example, GPT-4 (March 2023) was reasonable at identifying prime vs.\n",
      "composite numbers (84% accuracy) but GPT-4 (June 2023) was poor on these same\n",
      "questions (51% accuracy). This is partly explained by a drop in GPT-4's amenity\n",
      "to follow chain-of-thought prompting. Interestingly, GPT-3.5 was much better in\n",
      "June than in March in this task. GPT-4 became less willing to answer sensitive\n",
      "questions and opinion survey questions in June than in March. GPT-4 performed\n",
      "better at multi-hop questions in June than in March, while GPT-3.5's\n",
      "performance dropped on this task. Both GPT-4 and GPT-3.5 had more formatting\n",
      "mistakes in code generation in June than in March. We provide evidence that\n",
      "GPT-4's ability to follow user instructions has decreased over time, which is\n",
      "one common factor behind the many behavior drifts. Overall, our findings show\n",
      "that the behavior of the \"same\" LLM service can change substantially in a\n",
      "relatively short amount of time, highlighting the need for continuous\n",
      "monitoring of LLMs.\n",
      "arXiv ID: 2307.09009v3\n",
      "Link: http://arxiv.org/abs/2307.09009v3\n",
      "---\n",
      "Title: Gpt-4: A Review on Advancements and Opportunities in Natural Language\n",
      "  Processing\n",
      "Authors: [{'name': 'Jawid Ahmad Baktash'}, {'name': 'Mursal Dawodi'}]\n",
      "Published: 2023-05-04T22:46:43Z\n",
      "Summary: Generative Pre-trained Transformer 4 (GPT-4) is the fourth-generation\n",
      "language model in the GPT series, developed by OpenAI, which promises\n",
      "significant advancements in the field of natural language processing (NLP). In\n",
      "this research article, we have discussed the features of GPT-4, its potential\n",
      "applications, and the challenges that it might face. We have also compared\n",
      "GPT-4 with its predecessor, GPT-3. GPT-4 has a larger model size (more than one\n",
      "trillion), better multilingual capabilities, improved contextual understanding,\n",
      "and reasoning capabilities than GPT-3. Some of the potential applications of\n",
      "GPT-4 include chatbots, personal assistants, language translation, text\n",
      "summarization, and question-answering. However, GPT-4 poses several challenges\n",
      "and limitations such as computational requirements, data requirements, and\n",
      "ethical concerns.\n",
      "arXiv ID: 2305.03195v1\n",
      "Link: http://arxiv.org/abs/2305.03195v1\n",
      "---\n",
      "Title: Is GPT-4 a Good Data Analyst?\n",
      "Authors: [{'name': 'Liying Cheng'}, {'name': 'Xingxuan Li'}, {'name': 'Lidong Bing'}]\n",
      "Published: 2023-05-24T11:26:59Z\n",
      "Summary: As large language models (LLMs) have demonstrated their powerful capabilities\n",
      "in plenty of domains and tasks, including context understanding, code\n",
      "generation, language generation, data storytelling, etc., many data analysts\n",
      "may raise concerns if their jobs will be replaced by artificial intelligence\n",
      "(AI). This controversial topic has drawn great attention in public. However, we\n",
      "are still at a stage of divergent opinions without any definitive conclusion.\n",
      "Motivated by this, we raise the research question of \"is GPT-4 a good data\n",
      "analyst?\" in this work and aim to answer it by conducting head-to-head\n",
      "comparative studies. In detail, we regard GPT-4 as a data analyst to perform\n",
      "end-to-end data analysis with databases from a wide range of domains. We\n",
      "propose a framework to tackle the problems by carefully designing the prompts\n",
      "for GPT-4 to conduct experiments. We also design several task-specific\n",
      "evaluation metrics to systematically compare the performance between several\n",
      "professional human data analysts and GPT-4. Experimental results show that\n",
      "GPT-4 can achieve comparable performance to humans. We also provide in-depth\n",
      "discussions about our results to shed light on further studies before reaching\n",
      "the conclusion that GPT-4 can replace data analysts.\n",
      "arXiv ID: 2305.15038v2\n",
      "Link: http://arxiv.org/abs/2305.15038v2\n",
      "---\n",
      "Title: Graph Neural Architecture Search with GPT-4\n",
      "Authors: [{'name': 'Haishuai Wang'}, {'name': 'Yang Gao'}, {'name': 'Xin Zheng'}, {'name': 'Peng Zhang'}, {'name': 'Hongyang Chen'}, {'name': 'Jiajun Bu'}]\n",
      "Published: 2023-09-30T08:05:59Z\n",
      "Summary: Graph Neural Architecture Search (GNAS) has shown promising results in\n",
      "automatically designing graph neural networks. However, GNAS still requires\n",
      "intensive human labor with rich domain knowledge to design the search space and\n",
      "search strategy. In this paper, we integrate GPT-4 into GNAS and propose a new\n",
      "GPT-4 based Graph Neural Architecture Search method (GPT4GNAS for short). The\n",
      "basic idea of our method is to design a new class of prompts for GPT-4 to guide\n",
      "GPT-4 toward the generative task of graph neural architectures. The prompts\n",
      "consist of descriptions of the search space, search strategy, and search\n",
      "feedback of GNAS. By iteratively running GPT-4 with the prompts, GPT4GNAS\n",
      "generates more accurate graph neural networks with fast convergence.\n",
      "Experimental results show that embedding GPT-4 into GNAS outperforms the\n",
      "state-of-the-art GNAS methods.\n",
      "arXiv ID: 2310.01436v1\n",
      "Link: http://arxiv.org/abs/2310.01436v1\n",
      "---\n",
      "Title: Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with\n",
      "  Code-based Self-Verification\n",
      "Authors: [{'name': 'Aojun Zhou'}, {'name': 'Ke Wang'}, {'name': 'Zimu Lu'}, {'name': 'Weikang Shi'}, {'name': 'Sichun Luo'}, {'name': 'Zipeng Qin'}, {'name': 'Shaoqing Lu'}, {'name': 'Anya Jia'}, {'name': 'Linqi Song'}, {'name': 'Mingjie Zhan'}, {'name': 'Hongsheng Li'}]\n",
      "Published: 2023-08-15T17:58:45Z\n",
      "Summary: Recent progress in large language models (LLMs) like GPT-4 and PaLM-2 has\n",
      "brought significant advancements in addressing math reasoning problems. In\n",
      "particular, OpenAI's latest version of GPT-4, known as GPT-4 Code Interpreter,\n",
      "shows remarkable performance on challenging math datasets. In this paper, we\n",
      "explore the effect of code on enhancing LLMs' reasoning capability by\n",
      "introducing different constraints on the \\textit{Code Usage Frequency} of GPT-4\n",
      "Code Interpreter. We found that its success can be largely attributed to its\n",
      "powerful skills in generating and executing code, evaluating the output of code\n",
      "execution, and rectifying its solution when receiving unreasonable outputs.\n",
      "Based on this insight, we propose a novel and effective prompting method,\n",
      "explicit \\uline{c}ode-based \\uline{s}elf-\\uline{v}erification~(CSV), to further\n",
      "boost the mathematical reasoning potential of GPT-4 Code Interpreter. This\n",
      "method employs a zero-shot prompt on GPT-4 Code Interpreter to encourage it to\n",
      "use code to self-verify its answers. In instances where the verification state\n",
      "registers as ``False'', the model shall automatically amend its solution,\n",
      "analogous to our approach of rectifying errors during a mathematics\n",
      "examination. Furthermore, we recognize that the states of the verification\n",
      "result indicate the confidence of a solution, which can improve the\n",
      "effectiveness of majority voting. With GPT-4 Code Interpreter and CSV, we\n",
      "achieve an impressive zero-shot accuracy on MATH dataset \\textbf{(53.9\\% $\\to$\n",
      "84.3\\%)}.\n",
      "arXiv ID: 2308.07921v1\n",
      "Link: http://arxiv.org/abs/2308.07921v1\n",
      "---\n",
      "Title: OpenAI Cribbed Our Tax Example, But Can GPT-4 Really Do Tax?\n",
      "Authors: [{'name': 'Andrew Blair-Stanek'}, {'name': 'Nils Holzenberger'}, {'name': 'Benjamin Van Durme'}]\n",
      "Published: 2023-09-15T20:00:27Z\n",
      "Summary: The authors explain where OpenAI got the tax law example in its livestream\n",
      "demonstration of GPT-4, why GPT-4 got the wrong answer, and how it fails to\n",
      "reliably calculate taxes.\n",
      "arXiv ID: 2309.09992v1\n",
      "Link: http://arxiv.org/abs/2309.09992v1\n",
      "---\n",
      "Title: Large Language Models' Understanding of Math: Source Criticism and\n",
      "  Extrapolation\n",
      "Authors: [{'name': 'Roozbeh Yousefzadeh'}, {'name': 'Xuenan Cao'}]\n",
      "Published: 2023-11-12T07:52:32Z\n",
      "Summary: It has been suggested that large language models such as GPT-4 have acquired\n",
      "some form of understanding beyond the correlations among the words in text\n",
      "including some understanding of mathematics as well. Here, we perform a\n",
      "critical inquiry into this claim by evaluating the mathematical understanding\n",
      "of the GPT-4 model. Considering that GPT-4's training set is a secret, it is\n",
      "not straightforward to evaluate whether the model's correct answers are based\n",
      "on a mathematical understanding or based on replication of proofs that the\n",
      "model has seen before. We specifically craft mathematical questions which their\n",
      "formal proofs are not readily available on the web, proofs that are more likely\n",
      "not seen by the GPT-4. We see that GPT-4 is unable to solve those problems\n",
      "despite their simplicity. It is hard to find scientific evidence suggesting\n",
      "that GPT-4 has acquired an understanding of even basic mathematical concepts. A\n",
      "straightforward way to find failure modes of GPT-4 in theorem proving is to\n",
      "craft questions where their formal proofs are not available on the web. Our\n",
      "finding suggests that GPT-4's ability is to reproduce, rephrase, and polish the\n",
      "mathematical proofs that it has seen before, and not in grasping mathematical\n",
      "concepts. We also see that GPT-4's ability to prove mathematical theorems is\n",
      "continuously expanding over time despite the claim that it is a fixed model. We\n",
      "suggest that the task of proving mathematical theorems in formal language is\n",
      "comparable to the methods used in search engines such as Google while\n",
      "predicting the next word in a sentence may be a misguided approach, a recipe\n",
      "that often leads to excessive extrapolation and eventual failures. Prompting\n",
      "the GPT-4 over and over may benefit the GPT-4 and the OpenAI, but we question\n",
      "whether it is valuable for machine learning or for theorem proving.\n",
      "arXiv ID: 2311.07618v1\n",
      "Link: http://arxiv.org/abs/2311.07618v1\n",
      "---\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mData_scientist\u001B[0m (to chat_manager):\n",
      "\n",
      "Based on the search results, we have several papers that discuss GPT-4 and its capabilities. Here are some potential applications in software development and related domains as mentioned in the papers:\n",
      "\n",
      "1. **Dementia Diagnosis**: The first paper discusses the use of GPT-4 in dementia diagnosis, which, while not directly related to software development, indicates the potential for GPT-4 to assist in healthcare software applications by providing diagnostic support or decision-making assistance.\n",
      "\n",
      "2. **Reasoning and Problem Solving**: The second and third papers focus on GPT-4's reasoning abilities. While the second paper is skeptical of GPT-4's reasoning capabilities, the third paper suggests that GPT-4 shows promise in logical reasoning tasks. This could be applied to software development in the form of advanced debugging tools, where GPT-4 could help reason about code behavior and potential bugs.\n",
      "\n",
      "3. **Behavioral Changes Over Time**: The fourth paper examines how GPT-3.5 and GPT-4's behavior changes over time, including generating code. This could imply that GPT-4 could be used to monitor and adapt software systems over time, potentially leading to self-improving systems.\n",
      "\n",
      "4. **Natural Language Processing (NLP)**: The fifth paper reviews advancements in NLP due to GPT-4. Applications in software could include more sophisticated chatbots, improved language translation services, and enhanced text summarization tools that could be integrated into various software products.\n",
      "\n",
      "5. **Data Analysis**: The sixth paper asks if GPT-4 is a good data analyst. The findings suggest that GPT-4 can perform end-to-end data analysis, which could be applied to software development in the form of intelligent data analysis tools that assist developers in understanding user behavior, system performance, and other analytics.\n",
      "\n",
      "6. **Graph Neural Architecture Search**: The seventh paper introduces the use of GPT-4 in graph neural architecture search, which could revolutionize the way neural network architectures are designed within software, leading to more efficient and effective machine learning applications.\n",
      "\n",
      "7. **Math Word Problems and Code Interpretation**: The eighth paper explores GPT-4's ability to solve math word problems using code interpretation and self-verification. This could be applied to software development by using GPT-4 to write and verify complex algorithms or to assist in educational software that teaches programming and problem-solving skills.\n",
      "\n",
      "8. **Tax Calculation**: The ninth paper critically examines GPT-4's ability to handle tax calculations, which could be relevant for financial software development, although the paper points out limitations in GPT-4's current capabilities.\n",
      "\n",
      "9. **Mathematical Understanding**: The tenth paper questions GPT-4's understanding of mathematics, suggesting that its abilities may be more about reproducing known proofs rather than genuine understanding. This could have implications for software that relies on GPT-4 for mathematical modeling or simulations.\n",
      "\n",
      "In summary, GPT-4 has potential applications in software development ranging from NLP enhancements, code generation, debugging, data analysis, and even in the design of neural network architectures. However, the papers also highlight limitations and areas where GPT-4 may not yet be reliable enough to replace human expertise. It's important to consider these findings critically and to evaluate the practicality and reliability of integrating GPT-4 into software development processes on a case-by-case basis.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mMachine_learning_engineer\u001B[0m (to chat_manager):\n",
      "\n",
      "The insights provided by the data scientist are quite comprehensive. To add to the discussion, it's important to consider the following points:\n",
      "\n",
      "- **Scalability**: The integration of GPT-4 into software applications must be scalable. For instance, using GPT-4 for code generation or data analysis in a large-scale software project requires robust infrastructure to handle potentially high volumes of requests and data processing.\n",
      "\n",
      "- **Performance**: The performance of GPT-4, particularly in time-sensitive applications like real-time diagnostics or interactive tools, needs to be evaluated. The latency in response times and the computational resources required to run GPT-4 models could impact the user experience.\n",
      "\n",
      "- **Ethical Considerations**: The use of GPT-4 raises ethical questions, especially in applications like healthcare diagnosis or financial advice. The accuracy of the model's outputs and the potential for biases in its responses must be carefully considered.\n",
      "\n",
      "- **User Impact**: The integration of GPT-4 into software products should enhance the user experience, not complicate it. User studies and feedback are crucial to understanding how these applications affect the end-user.\n",
      "\n",
      "Given these considerations, it's also important to keep in mind the iterative nature of machine learning model deployment. Continuous monitoring, testing, and updating are necessary to ensure that the applications of GPT-4 remain effective and ethical.\n",
      "\n",
      "Collaboratively, we should also consider the following:\n",
      "\n",
      "- **Research and Development**: Further research is needed to improve GPT-4's capabilities and address its current limitations. This includes working on its reasoning abilities, understanding of complex subjects like tax law, and mathematical reasoning.\n",
      "\n",
      "- **Customization and Fine-tuning**: For specific software domains, GPT-4 might require fine-tuning with domain-specific data to improve its performance and relevance.\n",
      "\n",
      "- **Interdisciplinary Collaboration**: Collaboration between machine learning engineers, domain experts, and ethicists is essential to create applications that are not only technically sound but also socially responsible.\n",
      "\n",
      "In conclusion, while GPT-4 offers exciting opportunities for software development, its integration should be approached with careful consideration of its current limitations and potential impact. Continuous research and interdisciplinary collaboration will be key to unlocking its full potential in a responsible manner.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mNatural_language_processing_specialist\u001B[0m (to chat_manager):\n",
      "\n",
      "As a Natural Language Processing Specialist, I'd like to emphasize the importance of understanding the underlying mechanisms of GPT-4 and similar models when considering their integration into software applications. Here are some additional points to consider:\n",
      "\n",
      "- **Interpretability**: Understanding why GPT-4 makes certain decisions or provides specific outputs is crucial, especially for applications that require a high level of trust, such as healthcare or finance. Interpretability tools and methods should be developed alongside GPT-4 applications to provide transparency.\n",
      "\n",
      "- **Data Privacy**: GPT-4's training on vast amounts of data may raise concerns about data privacy, especially if the model is used in applications that handle sensitive information. Ensuring that GPT-4 applications comply with data protection regulations is essential.\n",
      "\n",
      "- **Continuous Learning**: The ability of GPT-4 to adapt to new information and learn from interactions is both an opportunity and a challenge. While it allows the model to improve over time, it also means that the model's behavior may change in unexpected ways, as highlighted in one of the papers.\n",
      "\n",
      "- **Language and Cultural Sensitivity**: GPT-4's multilingual capabilities suggest potential for global applications. However, cultural nuances and language-specific subtleties must be handled carefully to avoid misinterpretation and biases.\n",
      "\n",
      "- **Collaboration with Domain Experts**: To ensure the successful application of GPT-4 in software, collaboration with domain experts is necessary. They can provide the context and expertise needed to guide the model's outputs and ensure they are appropriate and useful.\n",
      "\n",
      "- **Tooling and Integration**: Developers will need tools and frameworks that facilitate the integration of GPT-4 into existing software systems. This includes APIs, SDKs, and other middleware that allow for seamless communication between GPT-4 and application-specific components.\n",
      "\n",
      "- **Evaluation and Metrics**: Establishing robust evaluation metrics and benchmarks is critical for assessing GPT-4's performance in software applications. These metrics should go beyond accuracy and include factors such as user satisfaction, efficiency gains, and return on investment.\n",
      "\n",
      "In summary, the potential applications of GPT-4 in software development are vast and varied. However, realizing these applications requires careful consideration of technical, ethical, and practical factors. As we move forward, it's important to maintain a dialogue between NLP specialists, machine learning engineers, data scientists, and other stakeholders to ensure that the development and deployment of GPT-4-powered software are aligned with societal values and user needs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mApplication_analyst\u001B[0m (to chat_manager):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_task(\n",
    "    execution_task=\"Find a recent paper about gpt-4 on arxiv and find its potential applications in software.\",\n",
    "    agent_list=agent_list,\n",
    "    llm_config=default_llm_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a30e4b4297edd1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 6 (Optional): clear all agents and prepare for the next task\n",
    "You can clear all agents generated in this task by the following code if your task is completed or the next task is largely different from the current task. If the agent's backbone is an open-source LLM, this process will also shut down the endpoint server. If necessary, you can use `recycle_endpoint=False` to retain the previous open-source LLMs' endpoint server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fb0bfff01dd1330",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:59:01.066007100Z",
     "start_time": "2024-01-01T08:59:01.051959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All agents have been cleared.\n"
     ]
    }
   ],
   "source": [
    "builder.clear_all_agents(recycle_endpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb098638a086898",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Save & load configs\n",
    "\n",
    "You can save all necessary information of the built group chat agents. Here is a case for those agents generated in the above task:\n",
    "```json\n",
    "{\n",
    "    \"building_task\": \"Find a paper on arxiv by programming, and analysis its application in some domain. For example, find a latest paper about gpt-4 on arxiv and find its potential applications in software.\",\n",
    "    \"agent_configs\": [\n",
    "        {\n",
    "            \"name\": \"Data_scientist\",\n",
    "            \"model\": \"gpt-4-1106-preview\",\n",
    "            \"system_message\": \"As a Data Scientist, you are tasked with automating the retrieval and analysis of academic papers from arXiv. Utilize your Python programming acumen to develop scripts for gathering necessary information such as searching for relevant papers, downloading them, and processing their contents. Apply your analytical and language skills to interpret the data and deduce the applications of the research within specific domains.\\n\\n1. To compile information, write and implement Python scripts that search and interact with online resources, download and read files, extract content from documents, and perform other information-gathering tasks. Use the printed output as the foundation for your subsequent analysis.\\n\\n2. Execute tasks programmatically with Python scripts when possible, ensuring results are directly displayed. Approach each task with efficiency and strategic thinking.\\n\\nProgress through tasks systematically. In instances where a strategy is not provided, outline your plan before executing. Clearly distinguish between tasks handled via code and those utilizing your analytical expertise.\\n\\nWhen providing code, include only Python scripts meant to be run without user alterations. Users should execute your script as is, without modifications:\\n\\n```python\\n# filename: <filename>\\n# Python script\\nprint(\\\"Your output\\\")\\n```\\n\\nUsers should not perform any actions other than running the scripts you provide. Avoid presenting partial or incomplete scripts that require user adjustments. Refrain from requesting users to copy-paste results; instead, use the 'print' function when suitable to display outputs. Monitor the execution results they share.\\n\\nIf an error surfaces, supply corrected scripts for a re-run. If the strategy fails to resolve the issue, reassess your assumptions, gather additional details as needed, and explore alternative approaches.\\n\\nUpon successful completion of a task and verification of the results, confirm the achievement of the stated objective. Ensuring accuracy and validity of the findings is paramount. Evidence supporting your conclusions should be provided when feasible.\\n\\nUpon satisfying the user's needs and ensuring all tasks are finalized, conclude your assistance with \\\"TERMINATE\\\".\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Research_analyst\",\n",
    "            \"model\": \"gpt-4-1106-preview\",\n",
    "            \"system_message\": \"As a Research Analyst, you are expected to be a proficient AI assistant possessing a strong grasp of programming, specifically in Python, and robust analytical capabilities. Your primary responsibilities will include:\\n\\n1. Conducting comprehensive searches and retrieving information autonomously through Python scripts, such as querying databases, accessing web services (like arXiv), downloading and reading files, and retrieving system information.\\n2. Analyzing the content of the retrieved documents, particularly academic papers, and extracting insights regarding their application in specific domains, such as the potential uses of GPT-4 in software development.\\n3. Presenting your findings in a clear, detailed manner, explaining the implications of the research and its relevance to the assigned task.\\n4. Employing your programming skills to automate tasks where possible, ensuring the output is delivered through Python code with clear, executable instructions. Your code will be designed for the user to execute without amendment or additional input.\\n5. Verifying the results of information gathering and analysis to ensure accuracy and completeness, providing evidence to support your conclusions when available.\\n6. Communicating the completion of each task and confirming that the user's needs have been satisfied through a clear and conclusive statement, followed by the word \\\"TERMINATE\\\" to signal the end of the interaction.\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Software_developer\",\n",
    "            \"model\": \"gpt-4-1106-preview\",\n",
    "            \"system_message\": \"As a dedicated AI assistant for a software developer, your role involves employing your Python programming prowess and proficiency in natural language processing to facilitate the discovery and analysis of scholarly articles on arXiv. Your tasks include crafting Python scripts to automatically search, retrieve, and present information regarding the latest research, with a focus on applicable advancements in technology such as GPT-4 and its potential impact on the domain of software development.\\n\\n1. Utilize Python to programmatically seek out and extract pertinent data, for example, navigating or probing the web, downloading/ingesting documents, or showcasing content from web pages or files. When enough information has been accumulated to proceed, you will then analyze and interpret the findings.\\n\\n2. When there's a need to perform an operation programmatically, your Python code should accomplish the task and manifest the outcome. Progress through the task incrementally and systematically.\\n\\nProvide a clear plan outlining each stage of the task, specifying which components will be executed through Python coding and which through your linguistic capabilities. When proposing Python code, remember to:\\n\\n- Label the script type within the code block\\n- Avoid suggesting code that the user would need to alter\\n- Refrain from including more than one code block in your response\\n- Circumvent requesting the user to manually transcribe any results; utilize 'print' statements where applicable\\n- Examine the user's reported execution outcomes\\n\\nIf an error arises, your responsibility is to rectify the issue and submit the corrected script. Should an error remain unresolvable, or if the task remains incomplete post successful code execution, re-evaluate the scenario, gather any further required information, and formulate an alternative approach.\\n\\nUpon confirming that the task has been satisfactorily accomplished and the user's requirements have been met, indicate closure of the procedure with a concluding statement.\"\n",
    "        }\n",
    "    ],\n",
    "    \"coding\": true,\n",
    "    \"default_llm_config\": {\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "}\n",
    "```\n",
    "These information will be saved in JSON format. You can provide a specific filename, otherwise, AgentBuilder will save config to the current path with a generated filename 'save_config_TASK_MD5.json'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4b88a5d482ceba4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:59:03.734870500Z",
     "start_time": "2024-01-01T08:59:03.723409200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building config saved to ./save_config_2a87f83309bd8b5ebb0423f5570385f5.json\n"
     ]
    }
   ],
   "source": [
    "saved_path = builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35620c10ee42be",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "After that, you can load the saved config and skip the building process. AgentBuilder will create agents with those information without prompting the builder manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34addd498e5ab174",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T09:00:19.478219200Z",
     "start_time": "2024-01-01T08:59:05.053688800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config from ./save_config_2a87f83309bd8b5ebb0423f5570385f5.json\n",
      "==> Creating agents...\n",
      "Creating agent Data_scientist with backbone gpt-4-1106-preview...\n",
      "Creating agent Machine_learning_engineer with backbone gpt-4-1106-preview...\n",
      "Creating agent Natural_language_processing_specialist with backbone gpt-4-1106-preview...\n",
      "Creating agent Arxiv_API_developer with backbone gpt-4-1106-preview...\n",
      "Creating agent Application_analyst with backbone gpt-4-1106-preview...\n",
      "Adding user console proxy...\n",
      "\u001B[33mUser_console_and_Python_code_interpreter\u001B[0m (to chat_manager):\n",
      "Find a recent paper about Llava on arxiv and find its potential applications in computer vision.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mArxiv_API_developer\u001B[0m (to chat_manager):\n",
      "\n",
      "To begin, I will craft a Python script that utilizes the arXiv API to search for recent papers related to \"Llava\" (assuming \"Llava\" is a keyword relevant to the field of computer vision; if it's a typo and you meant \"Lava\", please correct me). The script will query the arXiv database, filter the results for relevance and recency, and then extract the necessary information such as the title, authors, abstract, and publication date.\n",
      "\n",
      "Once we have the information on the paper(s), I will analyze the abstract and any available content to identify potential applications in computer vision. Please note that I will not be running the code but will provide you with the Python code that you can execute in your environment.\n",
      "\n",
      "Here's an example of how the Python code might look:\n",
      "\n",
      "```python\n",
      "import urllib\n",
      "import feedparser\n",
      "\n",
      "# Base API query url\n",
      "base_url = 'http://export.arxiv.org/api/query?'\n",
      "\n",
      "# Search parameters\n",
      "search_query = 'all:Llava' # search for the keyword Llava in all fields\n",
      "start = 0                     # start at the first result\n",
      "total_results = 1             # want a single result\n",
      "results_per_iteration = 1     # results per request\n",
      "wait_time = 3                 # wait time between requests\n",
      "\n",
      "# Opensearch metadata such as total results for the search query\n",
      "print('Searching arXiv for papers related to Llava...')\n",
      "\n",
      "# Run through each iteration to get all results\n",
      "for i in range(start, total_results, results_per_iteration):\n",
      "    query = 'search_query=%s&start=%i&max_results=%i' % (search_query,\n",
      "                                                         i,\n",
      "                                                         results_per_iteration)\n",
      "    with urllib.request.urlopen(base_url+query) as url:\n",
      "        response = url.read()\n",
      "    feed = feedparser.parse(response)\n",
      "    for entry in feed.entries:\n",
      "        print('Title: %s' % entry.title)\n",
      "        print('Authors: %s' % ', '.join(author.name for author in entry.authors))\n",
      "        print('Abstract: %s' % entry.summary)\n",
      "        print('Publication Date: %s' % entry.published)\n",
      "        # Here you can add code to analyze the abstract and identify potential applications in computer vision\n",
      "\n",
      "# Note: This code is for demonstration purposes and might not run as-is.\n",
      "```\n",
      "\n",
      "Please execute this code in your Python environment to retrieve the information. After obtaining the paper's details, I will proceed with the analysis based on the abstract and any other accessible content to discuss potential applications in computer vision.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001B[0m\n",
      "\u001B[33mUser_console_and_Python_code_interpreter\u001B[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Searching arXiv for papers related to Llava...\n",
      "Title: LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation,\n",
      "  Generation and Editing\n",
      "Authors: Wei-Ge Chen, Irina Spiridonova, Jianwei Yang, Jianfeng Gao, Chunyuan Li\n",
      "Abstract: LLaVA-Interactive is a research prototype for multimodal human-AI\n",
      "interaction. The system can have multi-turn dialogues with human users by\n",
      "taking multimodal user inputs and generating multimodal responses. Importantly,\n",
      "LLaVA-Interactive goes beyond language prompt, where visual prompt is enabled\n",
      "to align human intents in the interaction. The development of LLaVA-Interactive\n",
      "is extremely cost-efficient as the system combines three multimodal skills of\n",
      "pre-built AI models without additional model training: visual chat of LLaVA,\n",
      "image segmentation from SEEM, as well as image generation and editing from\n",
      "GLIGEN. A diverse set of application scenarios is presented to demonstrate the\n",
      "promises of LLaVA-Interactive and to inspire future research in multimodal\n",
      "interactive systems.\n",
      "Publication Date: 2023-11-01T15:13:43Z\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mData_scientist\u001B[0m (to chat_manager):\n",
      "\n",
      "Based on the output provided, we have identified a recent paper titled \"LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation, Generation and Editing\" authored by Wei-Ge Chen, Irina Spiridonova, Jianwei Yang, Jianfeng Gao, and Chunyuan Li. The paper was published on November 1, 2023.\n",
      "\n",
      "The abstract describes LLaVA-Interactive as a research prototype for multimodal human-AI interaction. It is capable of engaging in multi-turn dialogues with human users by processing multimodal inputs (both visual and textual) and generating multimodal responses. A key feature of LLaVA-Interactive is its ability to use visual prompts to better align with human intents during interactions.\n",
      "\n",
      "The system integrates three multimodal skills from pre-built AI models without the need for additional model training:\n",
      "1. Visual chat from LLaVA\n",
      "2. Image segmentation from SEEM\n",
      "3. Image generation and editing from GLIGEN\n",
      "\n",
      "Potential applications in computer vision, as suggested by the paper, include:\n",
      "\n",
      "1. **Interactive Image Editing**: Users can interact with the system to make changes to images, such as altering specific elements or overall aesthetics. This could be useful in fields like graphic design, digital marketing, and entertainment.\n",
      "\n",
      "2. **Image Segmentation**: The system can perform image segmentation, which is a fundamental task in computer vision with applications in medical imaging, autonomous vehicles, and photo editing.\n",
      "\n",
      "3. **Image Generation**: LLaVA-Interactive can generate images, which has potential applications in content creation, gaming, virtual reality, and data augmentation for training other machine learning models.\n",
      "\n",
      "4. **Visual Chat**: The ability to have a dialogue about visual content opens up possibilities for assistive technologies, educational tools, and enhanced user experiences in various software applications.\n",
      "\n",
      "5. **Multimodal Interaction**: The integration of visual and textual interaction can lead to more intuitive user interfaces for various applications, including search engines, e-commerce, and digital assistants.\n",
      "\n",
      "The development of LLaVA-Interactive is noted to be cost-efficient, which implies that it could be adopted by a wide range of industries looking to incorporate advanced computer vision capabilities without significant investment in model training.\n",
      "\n",
      "The paper presents a diverse set of application scenarios, which could inspire future research and development in multimodal interactive systems. It's important to note that while these applications are promising, the actual effectiveness and usability of the system would need to be evaluated in real-world settings.\n",
      "\n",
      "If there are specific aspects of the paper or potential applications you would like to explore further, please let me know, and I can delve deeper into those areas.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mMachine_learning_engineer\u001B[0m (to chat_manager):\n",
      "\n",
      "Given the information provided by the data scientist, it's clear that LLaVA-Interactive has a wide range of potential applications in the field of computer vision. To further enrich our analysis, we should consider the following aspects:\n",
      "\n",
      "1. **User Experience**: How intuitive and user-friendly is the interface of LLaVA-Interactive? The ease with which users can interact with the system will greatly affect its adoption and success.\n",
      "\n",
      "2. **Performance Metrics**: What are the performance metrics for the image segmentation, generation, and editing tasks? Understanding the accuracy, speed, and reliability of these tasks in various conditions is crucial for practical applications.\n",
      "\n",
      "3. **Scalability**: Can LLaVA-Interactive handle large-scale deployments? For instance, can it process high-resolution images or videos in real-time, which is often required in applications like surveillance or live broadcasting?\n",
      "\n",
      "4. **Ethical Considerations**: With the ability to generate and edit images, there are potential ethical concerns related to deepfakes and misinformation. How does LLaVA-Interactive address these issues?\n",
      "\n",
      "5. **Integration with Existing Systems**: How easily can LLaVA-Interactive be integrated with existing software systems or workflows? This will determine its practicality for companies that may want to enhance their current offerings with LLaVA-Interactive's capabilities.\n",
      "\n",
      "6. **Customization and Flexibility**: To what extent can LLaVA-Interactive be customized for specific applications or industries? Flexibility is key for a tool that aims to serve a wide range of use cases.\n",
      "\n",
      "7. **Data Privacy**: When dealing with user inputs, especially in multimodal forms, data privacy becomes a significant concern. It would be beneficial to understand how LLaVA-Interactive ensures the privacy and security of user data.\n",
      "\n",
      "8. **Limitations and Constraints**: Identifying any limitations or constraints of the system, such as dependency on certain types of data or computational resources, will help in assessing its practicality.\n",
      "\n",
      "9. **Benchmark Comparisons**: How does LLaVA-Interactive compare to other state-of-the-art systems in terms of functionality and performance? Benchmarking against other systems can provide a clearer picture of its competitive advantages or shortcomings.\n",
      "\n",
      "10. **Future Development**: What are the future development plans for LLaVA-Interactive? Understanding the roadmap can give insights into its long-term viability and potential growth in capabilities.\n",
      "\n",
      "By considering these additional aspects, we can provide a more comprehensive analysis of LLaVA-Interactive's potential applications in computer vision and its implications for various industries. If any team members have insights or data on these points, their input would be valuable for our collective understanding.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mApplication_analyst\u001B[0m (to chat_manager):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "All agents have been cleared.\n"
     ]
    }
   ],
   "source": [
    "new_builder = AgentBuilder(config_path=config_path)\n",
    "agent_list, agent_configs = new_builder.load(saved_path)  # load previous agent configs\n",
    "start_task(\n",
    "    execution_task=\"Find a recent paper about Llava on arxiv and find its potential applications in computer vision.\",\n",
    "    agent_list=agent_list,\n",
    "    llm_config=default_llm_config\n",
    ")\n",
    "new_builder.clear_all_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e0cf8f09eef5cd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Use OpenAI Assistant\n",
    "\n",
    "[The Assistants API](https://platform.openai.com/docs/assistants/overview) allows you to build AI assistants within your own applications. An Assistant has instructions and can leverage models, tools, and knowledge to respond to user queries.\n",
    "AutoBuild also support assistant api by adding `use_oai_assistant=True` to `build()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4051c25b2cd1918c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T09:22:06.696874300Z",
     "start_time": "2024-01-01T09:18:05.695605300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Generating agents...\n",
      "['Python_Developer', 'AI_Research_Scientist', 'Application_Analyst', 'Technical_Reviewer'] are generated.\n",
      "==> Generating system message...\n",
      "Preparing system message for Python_Developer\n",
      "Preparing system message for AI_Research_Scientist\n",
      "Preparing system message for Application_Analyst\n",
      "Preparing system message for Technical_Reviewer\n",
      "==> Generating description...\n",
      "Preparing description for Python_Developer\n",
      "Preparing description for AI_Research_Scientist\n",
      "Preparing description for Application_Analyst\n",
      "Preparing description for Technical_Reviewer\n",
      "==> Creating agents...\n",
      "Creating agent Python_Developer with backbone gpt-4-1106-preview...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "assistant Python_Developer does not exist, creating a new assistant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating agent AI_Research_Scientist with backbone gpt-4-1106-preview...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "assistant AI_Research_Scientist does not exist, creating a new assistant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating agent Application_Analyst with backbone gpt-4-1106-preview...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "assistant Application_Analyst does not exist, creating a new assistant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating agent Technical_Reviewer with backbone gpt-4-1106-preview...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "assistant Technical_Reviewer does not exist, creating a new assistant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding user console proxy...\n",
      "\u001B[33mUser_console_and_Python_code_interpreter\u001B[0m (to chat_manager):\n",
      "Find a recent paper about explainable AI on arxiv and find its potential applications in medical.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mPython_Developer\u001B[0m (to chat_manager):\n",
      "\n",
      "To accomplish the task of finding recent papers about explainable AI on arXiv and identifying their potential applications in the medical field, we will perform the following steps:\n",
      "\n",
      "1. Use the arXiv API to search for recent papers on explainable AI.\n",
      "2. Parse the search results to find a relevant paper.\n",
      "3. Extract potential applications in the medical field from the abstract or conclusion if available.\n",
      "\n",
      "Below is the Python script that uses the arXiv API to perform these steps:\n",
      "\n",
      "```python\n",
      "import urllib\n",
      "import urllib.request\n",
      "import feedparser\n",
      "\n",
      "# Define the query parameters for the arXiv API\n",
      "query_params = {\n",
      "    'search_query': 'all:explainable AI',\n",
      "    'sortBy': 'submittedDate',\n",
      "    'sortOrder': 'descending',\n",
      "    'max_results': 10\n",
      "}\n",
      "\n",
      "# Create the query URL for the arXiv API\n",
      "query_url = 'http://export.arxiv.org/api/query?' + urllib.parse.urlencode(query_params)\n",
      "\n",
      "# Function to search for papers on arXiv\n",
      "def search_arxiv(url):\n",
      "    with urllib.request.urlopen(url) as response:\n",
      "        feed = feedparser.parse(response.read())\n",
      "        for entry in feed.entries:\n",
      "            # Extract information from the entry\n",
      "            title = entry.title\n",
      "            authors = \", \".join(author.name for author in entry.authors)\n",
      "            published = entry.published\n",
      "            summary = entry.summary\n",
      "            \n",
      "            # Look for 'medical' keyword in summary\n",
      "            if 'medical' in summary.lower():\n",
      "                return {\n",
      "                    'title': title,\n",
      "                    'authors': authors,\n",
      "                    'published': published,\n",
      "                    'summary': summary\n",
      "                }\n",
      "\n",
      "# Perform the search and display the result\n",
      "paper = search_arxiv(query_url)\n",
      "if paper:\n",
      "    print(\"Title:\", paper['title'])\n",
      "    print(\"Authors:\", paper['authors'])\n",
      "    print(\"Published:\", paper['published'])\n",
      "    print(\"Summary:\", paper['summary'])\n",
      "else:\n",
      "    print(\"No recent papers found on 'explainable AI' with medical applications.\")\n",
      "```\n",
      "\n",
      "Running the script will output a recent paper from the arXiv with relevance to explainable AI and potential applications in the medical field.\n",
      "\n",
      "Keep in mind that we are looking for matches of the word 'medical' in the summary to identify potential applications in the medical field. This may not cover all possible matches, but it is a good starting point for demonstration purposes.\n",
      "\n",
      "Please run the code in your Python environment, as I can't execute the code myself. If you encounter any issues or need further assistance, feel free to ask.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001B[0m\n",
      "\u001B[33mUser_console_and_Python_code_interpreter\u001B[0m (to chat_manager):\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "No recent papers found on 'explainable AI' with medical applications.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mTechnical_Reviewer\u001B[0m (to chat_manager):\n",
      "\n",
      "It appears that the script did not find any recent papers on 'explainable AI' with direct references to medical applications in their summaries. However, this doesn't necessarily mean that there are no recent relevant papers; it might be that the search criteria are too narrow or that the keywords used did not match the contents of the summaries.\n",
      "\n",
      "To broaden the search, we can consider the following adjustments:\n",
      "\n",
      "- Modify the search query to include terms that are closely related to 'medical', such as 'health', 'clinical', 'diagnosis', or 'treatment'.\n",
      "- Increase the `max_results` number to look through a larger set of papers.\n",
      "- Search within the full text of papers (if available) rather than just the summary.\n",
      "\n",
      "Since I do not have the capability to run scripts, I would recommend updating the script to include a broader range of search terms and possibly a larger set of results. After adjusting the script, please execute it again to see if any relevant papers can be found.\n",
      "\n",
      "Alternatively, if you want to explore further without running another script, you can manually search on arXiv using its search functionality with different keywords and filters to find a relevant paper on explainable AI with applications in the medical field.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mPython_Developer\u001B[0m (to chat_manager):\n",
      "\n",
      "Understood, let's broaden the search criteria a bit. We will incorporate multiple keywords such as 'health', 'clinical', 'diagnosis', and 'treatment' and increase the `max_results` parameter to look at more papers.\n",
      "\n",
      "Here is the updated Python script:\n",
      "\n",
      "```python\n",
      "import urllib\n",
      "import urllib.request\n",
      "import feedparser\n",
      "import re\n",
      "\n",
      "# Define the query parameters for the arXiv API\n",
      "query_params = {\n",
      "    'search_query': 'all:explainable AI',\n",
      "    'sortBy': 'submittedDate',\n",
      "    'sortOrder': 'descending',\n",
      "    'max_results': 50\n",
      "}\n",
      "\n",
      "# Create the query URL for the arXiv API\n",
      "query_url = 'http://export.arxiv.org/api/query?' + urllib.parse.urlencode(query_params)\n",
      "\n",
      "# Function to search for papers on arXiv\n",
      "def search_arxiv(url):\n",
      "    with urllib.request.urlopen(url) as response:\n",
      "        feed = feedparser.parse(response.read())\n",
      "        for entry in feed.entries:\n",
      "            # Extract information from the entry\n",
      "            title = entry.title\n",
      "            authors = \", \".join(author.name for author in entry.authors)\n",
      "            published = entry.published\n",
      "            summary = entry.summary\n",
      "            \n",
      "            # Check for medical-related keywords in the summary using regex\n",
      "            if re.search(r'\\b(health|clinical|diagnosis|treatment)\\b', summary, re.IGNORECASE):\n",
      "                return {\n",
      "                    'title': title,\n",
      "                    'authors': authors,\n",
      "                    'published': published,\n",
      "                    'summary': summary\n",
      "                }\n",
      "\n",
      "# Perform the search and display the result\n",
      "paper = search_arxiv(query_url)\n",
      "if paper:\n",
      "    print(\"Title:\", paper['title'])\n",
      "    print(\"Authors:\", paper['authors'])\n",
      "    print(\"Published:\", paper['published'])\n",
      "    print(\"Summary:\", paper['summary'])\n",
      "else:\n",
      "    print(\"No recent papers found on 'explainable AI' with potential applications in the medical field.\")\n",
      "\n",
      "```\n",
      "\n",
      "This script searches for the recent papers about \"explainable AI\" on arXiv and looks for medical-related keywords in the summary of each paper. We've increased the `max_results` to 50 to have a broader set of papers to look through.\n",
      "\n",
      "Please run the script, and let me know if it finds a relevant paper.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001B[0m\n",
      "\u001B[33mUser_console_and_Python_code_interpreter\u001B[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Title: XAI for In-hospital Mortality Prediction via Multimodal ICU Data\n",
      "Authors: Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He\n",
      "Published: 2023-12-29T14:28:04Z\n",
      "Summary: Predicting in-hospital mortality for intensive care unit (ICU) patients is\n",
      "key to final clinical outcomes. AI has shown advantaged accuracy but suffers\n",
      "from the lack of explainability. To address this issue, this paper proposes an\n",
      "eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,\n",
      "explainable AI solution for predicting in-hospital mortality via multimodal ICU\n",
      "data. We employ multimodal learning in our framework, which can receive\n",
      "heterogeneous inputs from clinical data and make decisions. Furthermore, we\n",
      "introduce an explainable method, namely Layer-Wise Propagation to Transformer,\n",
      "as a proper extension of the LRP method to Transformers, producing explanations\n",
      "over multimodal inputs and revealing the salient features attributed to\n",
      "prediction. Moreover, the contribution of each modality to clinical outcomes\n",
      "can be visualized, assisting clinicians in understanding the reasoning behind\n",
      "decision-making. We construct a multimodal dataset based on MIMIC-III and\n",
      "MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on\n",
      "benchmark datasets demonstrate that our proposed framework can achieve\n",
      "reasonable interpretation with competitive prediction accuracy. In particular,\n",
      "our framework can be easily transferred to other clinical tasks, which\n",
      "facilitates the discovery of crucial factors in healthcare research.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mAI_Research_Scientist\u001B[0m (to chat_manager):\n",
      "\n",
      "The paper titled \"XAI for In-hospital Mortality Prediction via Multimodal ICU Data\" by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, and Fengxiang He presents an approach to enhance the explainability of AI systems in the context of in-hospital mortality prediction for ICU patients. Here's an analysis of the study:\n",
      "\n",
      "**Methodology**\n",
      "- The study introduces an eXplainable Multimodal Mortality Predictor (X-MMP) which utilizes multimodal learning capable of processing heterogeneous inputs from clinical data.\n",
      "- The authors implement an extension of the Layer-Wise Relevance Propagation (LRP) method specifically tailored for Transformers, dubbed Layer-Wise Propagation to Transformer (LPT), to produce explanations over multimodal inputs.\n",
      "- They also offer the capacity to visualize the contribution of each modality to clinical outcomes, promoting better understanding by clinicians of the model's decision-making process.\n",
      "\n",
      "**Results**\n",
      "- The X-MMP was tested on a dataset constructed from MIMIC-III and MIMIC-III Waveform Database Matched Subset, demonstrating reasonable interpretability alongside competitive prediction accuracy.\n",
      "- The framework promises ease of transferability to other clinical tasks, which could be instrumental for identifying critical factors in various healthcare research domains.\n",
      "\n",
      "**Implications for Medical Applications**\n",
      "- **Mortality Prediction**: By improving prediction and explanation capabilities, the X-MMP could play a significant role in informing clinical decisions related to ICU patient outcomes, potentially saving lives by better foreseeing complications.\n",
      "- **Clinical Decision Support**: The visual explanations of the contributions made by different data modalities may serve as a useful tool for clinicians, thus offering a more transparent clinical decision support system.\n",
      "- **Research and Development**: The transferable nature of the X-MMP framework means it could be applied in other healthcare prediction tasks, enhancing research across various clinical domains.\n",
      "- **Trust and Adoption**: Enhancing explainability could increase the trustworthiness of AI within clinical settings, encouraging broader adoption.\n",
      "- **Regulatory Compliance**: Explainable models can help in meeting regulatory requirements, offering clarity on how decisions are made for the safety and efficacy evaluations.\n",
      "\n",
      "It is essential to scrutinize the robustness and generalizability of such models, and to ensure that the explanations provided align well with the clinical understanding and practices. Given these precautions, the potential applications in the medical sector appear promising.\n",
      "\n",
      "**TERMINATE**\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mTechnical_Reviewer\u001B[0m (to chat_manager):\n",
      "\n",
      "Your task has been completed successfully, and the group chat acknowledges the termination of this session.\n",
      "\n",
      "If any further assistance or inquiry is needed in the future, feel free to initiate a new discussion.\n",
      "\n",
      "Goodbye!\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mAI_Research_Scientist\u001B[0m (to chat_manager):\n",
      "Goodbye, and feel free to reach out if there are any more tasks or discussions in the future. Have a great day!\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mAI_Research_Scientist\u001B[0m (to chat_manager):\n",
      "Goodbye, and feel free to reach out if you need any further assistance in the future. Have a great day!\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mTechnical_Reviewer\u001B[0m (to chat_manager):\n",
      "Goodbye! Don't hesitate to ask if you ever require further assistance. Have a wonderful day ahead!\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[33mUser_console_and_Python_code_interpreter\u001B[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "All agents have been cleared.\n"
     ]
    }
   ],
   "source": [
    "new_builder = AgentBuilder(config_path=config_path, builder_model='gpt-4-1106-preview', agent_model='gpt-4-1106-preview')\n",
    "agent_list, agent_configs = new_builder.build(building_task, default_llm_config, use_oai_assistant=True)  # Transfer to OpenAI assistant API.\n",
    "start_task(\n",
    "    execution_task=\"Find a recent paper about explainable AI on arxiv and find its potential applications in medical.\",\n",
    "    agent_list=agent_list,\n",
    "    llm_config=default_llm_config\n",
    ")\n",
    "new_builder.clear_all_agents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "99bdc75f8810926a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
