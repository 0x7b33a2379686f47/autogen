{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be5a8d87",
   "metadata": {},
   "source": [
    "# Use AutoGen in Microsoft Fabric\n",
    "\n",
    "AutoGen offers conversable LLM agents, which can be used to solve various tasks with human or automatic feedback, including tasks that require using tools via code.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "[Microsoft Fabric](https://learn.microsoft.com/en-us/fabric/get-started/microsoft-fabric-overview) is an all-in-one analytics solution for enterprises that covers everything from data movement to data science, Real-Time Analytics, and business intelligence. It offers a comprehensive suite of services, including data lake, data engineering, and data integration, all in one place. Its pre-built AI models include GPT-x models such as `gpt-4-turbo`, `gpt-4`, `gpt-4-8k`, `gpt-4-32k`, `gpt-35-turbo`, `gpt-35-turbo-16k` and `gpt-35-turbo-instruct`.\n",
    "\n",
    "In this notebook, we demonstrate how to use `AssistantAgent` and `UserProxyAgent` to perform a task which require acquiring info from the web:\n",
    "* discuss a paper based on its URL.\n",
    "\n",
    "Here `AssistantAgent` is an LLM-based agent that can write Python code (in a Python coding block) for a user to execute for a given task. `UserProxyAgent` is an agent which serves as a proxy for a user to execute the code written by `AssistantAgent`. By setting `human_input_mode` properly, the `UserProxyAgent` can also prompt the user for feedback to `AssistantAgent`. For example, when `human_input_mode` is set to \"TERMINATE\", the `UserProxyAgent` will execute the code written by `AssistantAgent` directly and return the execution results (success or failure and corresponding outputs) to `AssistantAgent`, and prompt the user for feedback when the task is finished. When user feedback is provided, the `UserProxyAgent` will directly pass the feedback to `AssistantAgent`.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install pyautogen:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```\n",
    "\n",
    "Also, this notebook depends on Microsoft Fabric pre-built LLM endpoints. Running it elsewhere may encounter errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83867b85-6fb2-4ca1-8859-206f0b854b24",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2023-12-09T08:45:42.6248547Z",
       "execution_start_time": "2023-12-09T08:45:42.6246012Z",
       "livy_statement_state": "available",
       "parent_msg_id": "181d1a32-78be-435d-b6cd-bf622b5af20e",
       "queued_time": "2023-12-09T08:45:14.164084Z",
       "session_id": null,
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": -1
      },
      "text/plain": [
       "StatementMeta(, , -1, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {},
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: PySpark kernel has been restarted to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install pyautogen -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c485fcab",
   "metadata": {},
   "source": [
    "## Set your API endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13005ac5-7f2a-4ba6-85b9-d45671093be2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2023-12-09T08:45:51.2882531Z",
       "execution_start_time": "2023-12-09T08:45:47.6341868Z",
       "livy_statement_state": "available",
       "parent_msg_id": "ab0656d5-fdce-4f60-a215-9dc4757f23b6",
       "queued_time": "2023-12-09T08:45:14.1654622Z",
       "session_id": "339dbc6f-779f-40b8-a484-08b1cda777f3",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 9
      },
      "text/plain": [
       "StatementMeta(, 339dbc6f-779f-40b8-a484-08b1cda777f3, 9, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09:08:45:47,911 WARNING  [synapse_mlflow_utils.py:244] To save or load Apache Spark model files, please attach a Lakehouse.\n"
     ]
    }
   ],
   "source": [
    "from synapse.ml.mlflow import get_mlflow_env_config\n",
    "\n",
    "mlflow_env_configs = get_mlflow_env_config()\n",
    "access_token = mlflow_env_configs.driver_aad_token\n",
    "prebuilt_AI_base_url = mlflow_env_configs.workload_endpoint + \"cognitive/openai/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1470b833-9cf2-4735-a28d-57d30714f562",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2023-12-09T08:45:52.2197083Z",
       "execution_start_time": "2023-12-09T08:45:51.764997Z",
       "livy_statement_state": "available",
       "parent_msg_id": "d81466b6-c0cb-49bc-91f2-db45bc12523e",
       "queued_time": "2023-12-09T08:45:14.1668841Z",
       "session_id": "339dbc6f-779f-40b8-a484-08b1cda777f3",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 10
      },
      "text/plain": [
       "StatementMeta(, 339dbc6f-779f-40b8-a484-08b1cda777f3, 10, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': access_token,\n",
    "        'base_url': prebuilt_AI_base_url,\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-08-01-preview',\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "llm_config={\n",
    "    \"timeout\": 600,\n",
    "    \"cache_seed\": 42,\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebbfec6-4683-4f42-b83d-37818a3fd451",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Construct Agents\n",
    "\n",
    "We construct the assistant agent and the user proxy agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951c0d05-1d58-4b42-88ea-7303c1da88aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2023-12-09T08:46:45.0006504Z",
       "execution_start_time": "2023-12-09T08:45:52.7820106Z",
       "livy_statement_state": "available",
       "parent_msg_id": "85ddc763-b26d-4350-bfd0-6712c6dd42e3",
       "queued_time": "2023-12-09T08:45:14.1678688Z",
       "session_id": "339dbc6f-779f-40b8-a484-08b1cda777f3",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 11
      },
      "text/plain": [
       "StatementMeta(, 339dbc6f-779f-40b8-a484-08b1cda777f3, 11, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import autogen\n",
    "\n",
    "# create an AssistantAgent instance named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",  # input() doesn't work, so needs to be \"NEVER\" here\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,  # set to True or image name like \"python:3\" to use docker\n",
    "    },\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"Reply TERMINATE if the task has been solved at full satisfaction.\n",
    "Otherwise, reply CONTINUE, or the reason why the task is not solved yet.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c340a5f5-068f-4374-bf6f-c7b628ab746a",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Example Task: Paper Talk from URL\n",
    "\n",
    "We invoke the `initiate_chat()` method of the user proxy agent to start the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf5798-b42b-4177-a6d1-dfb493020f19",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2023-12-09T08:47:06.698536Z",
       "execution_start_time": "2023-12-09T08:46:46.0039247Z",
       "livy_statement_state": "available",
       "parent_msg_id": "0c511a1f-e50e-4530-840d-af2ef1fa5396",
       "queued_time": "2023-12-09T08:45:14.1686938Z",
       "session_id": "339dbc6f-779f-40b8-a484-08b1cda777f3",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 12
      },
      "text/plain": [
       "StatementMeta(, 339dbc6f-779f-40b8-a484-08b1cda777f3, 12, Finished, Available)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "\n",
      "Who should read this paper: https://arxiv.org/abs/2308.08155\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "To determine who should read the paper, we first need to understand the content of the paper. We can do this by fetching the abstract of the paper from the provided URL and analyzing it. \n",
      "\n",
      "Here is a Python script that uses the BeautifulSoup library to scrape the abstract from the webpage.\n",
      "\n",
      "```python\n",
      "# filename: fetch_abstract.py\n",
      "\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def fetch_abstract(url):\n",
      "    response = requests.get(url)\n",
      "    soup = BeautifulSoup(response.text, 'html.parser')\n",
      "    abstract = soup.find('blockquote', attrs={'class': 'abstract mathjax'}).text.strip()\n",
      "    return abstract\n",
      "\n",
      "url = \"https://arxiv.org/abs/2308.08155\"\n",
      "print(fetch_abstract(url))\n",
      "```\n",
      "\n",
      "Please save this script as `fetch_abstract.py` and run it. This will print the abstract of the paper. Based on the abstract, I can then suggest who might be interested in reading the paper.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Abstract:AutoGen is an open-source framework that allows developers to build LLM applications via multiple agents that can converse with each other to accomplish tasks. AutoGen agents are customizable, conversable, and can operate in various modes that employ combinations of LLMs, human inputs, and tools. Using AutoGen, developers can also flexibly define agent interaction behaviors. Both natural language and computer code can be used to program flexible conversation patterns for different applications. AutoGen serves as a generic infrastructure to build diverse applications of various complexities and LLM capacities. Empirical studies demonstrate the effectiveness of the framework in many example applications, with domains ranging from mathematics, coding, question answering, operations research, online decision-making, entertainment, etc.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Based on the abstract, the paper is about AutoGen, an open-source framework that allows developers to build applications using multiple agents that can converse with each other to accomplish tasks. The framework is customizable and can operate in various modes that employ combinations of language models, human inputs, and tools. It can be used to program flexible conversation patterns for different applications using both natural language and computer code.\n",
      "\n",
      "Given this, the paper would be of interest to:\n",
      "\n",
      "1. **Software Developers and Engineers**: Especially those interested in building applications that involve multiple interacting agents, or those interested in using language models in their applications.\n",
      "\n",
      "2. **Researchers in Artificial Intelligence and Machine Learning**: The paper discusses a framework for building applications with language models, which is a hot topic in AI and ML research.\n",
      "\n",
      "3. **Data Scientists**: They might be interested in the applications of language models and how they can be used in a practical setting.\n",
      "\n",
      "4. **Students studying Computer Science, AI, or related fields**: The paper could provide valuable insights into the practical applications of language models and multi-agent systems.\n",
      "\n",
      "5. **Professionals in fields like mathematics, coding, operations research, online decision-making, entertainment, etc.**: As the paper mentions that the framework has been effectively used in these domains.\n",
      "\n",
      "Please note that this is a general suggestion. The paper could be of interest to anyone who wants to learn about the AutoGen framework and its applications. \n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# the assistant receives a message from the user, which contains the task description\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"\n",
    "Who should read this paper: https://arxiv.org/abs/2308.08155\n",
    "\"\"\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "notebook_environment": {},
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "save_output": true,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {},
    "enableDebugMode": false
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
